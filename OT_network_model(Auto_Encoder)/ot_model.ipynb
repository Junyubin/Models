{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ot_network_detection_utils import *\n",
    "from base_component import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import f1_score,accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization, Dropout, Input, GaussianNoise, LSTM, RepeatVector, TimeDistributed, Conv2D, MaxPooling2D, Flatten, UpSampling2D, Input, Reshape, Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model, model_from_json, load_model, Sequential\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.metrics import categorical_accuracy, RootMeanSquaredError\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K \n",
    "from clickhouse_driver import Client\n",
    "import warnings\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' ## 44서버 GPU ERROR\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pwd = os.getcwd()\n",
    "\n",
    "# 보령 화력발전소 제 5호기 데이터\n",
    "data = pd.read_csv('BO_5_new_data.csv')\n",
    "data.set_index('time', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"common\": {\n",
    "        \"model_name\": \"ot_model\",\n",
    "        \"scaler\":\"minmaxscaler\",\n",
    "        \"vec\":\"vectorization\",\n",
    "        \"path\": \"corr_model\"        \n",
    "    },\n",
    "    \"train\": {\n",
    "        \"data_load\": 0,\n",
    "        \"optimizer_help\": ['Adam', 'SGD'],\n",
    "        \"optimizer\": 'Adam',\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"batch_size\": 128,\n",
    "        \"epochs\": 500,\n",
    "        \"result_table\": \"result\"\n",
    "    },\n",
    "    \"predict\": {\n",
    "        \"batch_size\": 8\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** success! load_json model_config.json **********\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Version Setting\"\"\"    \n",
    "model_config = load_json('model_config.json')\n",
    "start = datetime.now().replace(microsecond=0) + timedelta(hours=9)\n",
    "train_version = start.strftime(\"%Y%m%d_%H\")\n",
    "model_name = train_version + '/' + model_config[\"common\"][\"model_name\"]\n",
    "minmaxscaler_save = train_version + '/' + model_config[\"common\"][\"scaler\"]\n",
    "if not os.path.exists(pwd+'/ot_model/'+train_version):\n",
    "    os.makedirs(pwd+'/ot_model/'+train_version)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA SPLIT & PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ ##### 시계열 데이터 특성으로 인해 데이터 셔플 하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_shape : (7318, 4071)\n",
      "data label count : \n",
      " 0    6952\n",
      "1     366\n",
      "Name: label, dtype: int64\n",
      "No. of training examples: 5122\n",
      "No. of testing examples: 2196\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Data Load \"\"\"\n",
    "# 보령 화력발전소 제 5호기 데이터\n",
    "data = pd.read_csv('BO_5_new_data.csv')\n",
    "data.set_index('time', inplace = True)\n",
    "print(\"data_shape : {}\".format(data.shape))\n",
    "print(\"data label count : \\n {}\".format(data.label.value_counts()))\n",
    "\n",
    "\"\"\" Data Split \"\"\"\n",
    "y = data['label']\n",
    "x = data.drop('label', axis = 1)\n",
    "train_late = 0.7\n",
    "train_len = int(len(data) * train_late)\n",
    "train_x, test_x = x[:train_len].copy(), x[train_len:].copy()\n",
    "train_y, test_y = y[:train_len].copy(), y[train_len:].copy()\n",
    "print(f\"No. of training examples: {train_x.shape[0]}\")\n",
    "print(f\"No. of testing examples: {test_x.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X Data Shape : (5122, 4070)\n",
      "Train Y Data Shape : (5122,)\n",
      "Train Y value counts :  \n",
      " 0    4862\n",
      "1     260\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Data Preprocessing \"\"\"\n",
    "## 데이터 스케일링\n",
    "def scale_module(data, mode = ['fit', 'trans']):\n",
    "    if mode == 'fit':\n",
    "        global scl_model\n",
    "        scl_model = MinMaxScaler()\n",
    "        scl_model.fit(data)\n",
    "        with open('{}/ot_model/{}.pickle'.format(pwd, minmaxscaler_save), \"wb\") as fw:\n",
    "            pickle.dump(scl_model, fw)\n",
    "        df = pd.DataFrame(index = data.index, columns = list(data), data = scl_model.transform(data))\n",
    "    else:\n",
    "        with open('{}/ot_model/{}.pickle'.format(pwd,minmaxscaler_save), \"rb\") as fr:\n",
    "            scl_model = pickle.load(fr)\n",
    "        df = pd.DataFrame(index = data.index, columns = list(data), data = scl_model.transform(data))\n",
    "    return df\n",
    "\n",
    "train_x = scale_module(train_x, mode = 'fit')\n",
    "print(\"Train X Data Shape : {}\".format(train_x.shape))\n",
    "print(\"Train Y Data Shape : {}\".format(train_y.shape))\n",
    "print(\"Train Y value counts :  \\n {}\".format(train_y.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               2084352   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4070)              2087910   \n",
      "=================================================================\n",
      "Total params: 4,320,550\n",
      "Trainable params: 4,320,550\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "41/41 [==============================] - 1s 5ms/step - loss: 0.2668 - mse: 0.2668\n",
      "Epoch 2/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1516 - mse: 0.1516\n",
      "Epoch 3/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1436 - mse: 0.1436\n",
      "Epoch 4/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1406 - mse: 0.1406\n",
      "Epoch 5/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1368 - mse: 0.1368\n",
      "Epoch 6/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1327 - mse: 0.1327\n",
      "Epoch 7/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.1280 - mse: 0.1280\n",
      "Epoch 8/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1247 - mse: 0.1247\n",
      "Epoch 9/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1214 - mse: 0.1214\n",
      "Epoch 10/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1184 - mse: 0.1184\n",
      "Epoch 11/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.1154 - mse: 0.1154\n",
      "Epoch 12/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.1130 - mse: 0.1130\n",
      "Epoch 13/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1107 - mse: 0.1107\n",
      "Epoch 14/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1100 - mse: 0.1100\n",
      "Epoch 15/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1081 - mse: 0.1081\n",
      "Epoch 16/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1071 - mse: 0.1071\n",
      "Epoch 17/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1061 - mse: 0.1061\n",
      "Epoch 18/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.1057 - mse: 0.1057\n",
      "Epoch 19/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1048 - mse: 0.1048\n",
      "Epoch 20/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1043 - mse: 0.1043\n",
      "Epoch 21/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1038 - mse: 0.1038\n",
      "Epoch 22/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.1032 - mse: 0.1032\n",
      "Epoch 23/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1027 - mse: 0.1027\n",
      "Epoch 24/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.1021 - mse: 0.1021\n",
      "Epoch 25/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1016 - mse: 0.1016\n",
      "Epoch 26/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1007 - mse: 0.1007\n",
      "Epoch 27/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.1003 - mse: 0.1003\n",
      "Epoch 28/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1000 - mse: 0.1000\n",
      "Epoch 29/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0993 - mse: 0.0993\n",
      "Epoch 30/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0985 - mse: 0.0985\n",
      "Epoch 31/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0979 - mse: 0.0979\n",
      "Epoch 32/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0980 - mse: 0.0980\n",
      "Epoch 33/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0975 - mse: 0.0975\n",
      "Epoch 34/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0966 - mse: 0.0966\n",
      "Epoch 35/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0963 - mse: 0.0963\n",
      "Epoch 36/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0959 - mse: 0.0959\n",
      "Epoch 37/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0959 - mse: 0.0959\n",
      "Epoch 38/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0953 - mse: 0.0953\n",
      "Epoch 39/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0952 - mse: 0.0952\n",
      "Epoch 40/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0945 - mse: 0.0945\n",
      "Epoch 41/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0941 - mse: 0.0941\n",
      "Epoch 42/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0936 - mse: 0.0936\n",
      "Epoch 43/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0929 - mse: 0.0929\n",
      "Epoch 44/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0917 - mse: 0.0917\n",
      "Epoch 45/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0905 - mse: 0.0905\n",
      "Epoch 46/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0904 - mse: 0.0904\n",
      "Epoch 47/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0900 - mse: 0.0900\n",
      "Epoch 48/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0900 - mse: 0.0900\n",
      "Epoch 49/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0898 - mse: 0.0898\n",
      "Epoch 50/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0896 - mse: 0.0896\n",
      "Epoch 51/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0889 - mse: 0.0889\n",
      "Epoch 52/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0887 - mse: 0.0887\n",
      "Epoch 53/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0881 - mse: 0.0881\n",
      "Epoch 54/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0874 - mse: 0.0874\n",
      "Epoch 55/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0869 - mse: 0.0869\n",
      "Epoch 56/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0862 - mse: 0.0862\n",
      "Epoch 57/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0851 - mse: 0.0851\n",
      "Epoch 58/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0849 - mse: 0.0849\n",
      "Epoch 59/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0846 - mse: 0.0846\n",
      "Epoch 60/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0843 - mse: 0.0843\n",
      "Epoch 61/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0842 - mse: 0.0842\n",
      "Epoch 62/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0841 - mse: 0.0841\n",
      "Epoch 63/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0841 - mse: 0.0841\n",
      "Epoch 64/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0842 - mse: 0.0842\n",
      "Epoch 65/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0826 - mse: 0.0826\n",
      "Epoch 66/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0823 - mse: 0.0823\n",
      "Epoch 67/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0819 - mse: 0.0819\n",
      "Epoch 68/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0818 - mse: 0.0818\n",
      "Epoch 69/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0808 - mse: 0.0808\n",
      "Epoch 70/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0803 - mse: 0.0803\n",
      "Epoch 71/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0798 - mse: 0.0798\n",
      "Epoch 72/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0789 - mse: 0.0789\n",
      "Epoch 73/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0784 - mse: 0.0784\n",
      "Epoch 74/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0780 - mse: 0.0780\n",
      "Epoch 75/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0778 - mse: 0.0778\n",
      "Epoch 76/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0779 - mse: 0.0779\n",
      "Epoch 77/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0779 - mse: 0.0779\n",
      "Epoch 78/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0777 - mse: 0.0777\n",
      "Epoch 79/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0773 - mse: 0.0773\n",
      "Epoch 80/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0773 - mse: 0.0773\n",
      "Epoch 81/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0772 - mse: 0.0772\n",
      "Epoch 82/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0769 - mse: 0.0769\n",
      "Epoch 83/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0766 - mse: 0.0766\n",
      "Epoch 84/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0766 - mse: 0.0766\n",
      "Epoch 85/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0759 - mse: 0.0759\n",
      "Epoch 86/500\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0757 - mse: 0.0757\n",
      "Epoch 87/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0755 - mse: 0.0755\n",
      "Epoch 88/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0748 - mse: 0.0748\n",
      "Epoch 89/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0746 - mse: 0.0746\n",
      "Epoch 90/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0744 - mse: 0.0744\n",
      "Epoch 91/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0741 - mse: 0.0741\n",
      "Epoch 92/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0734 - mse: 0.0734\n",
      "Epoch 93/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0729 - mse: 0.0729\n",
      "Epoch 94/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0731 - mse: 0.0731\n",
      "Epoch 95/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0725 - mse: 0.0725\n",
      "Epoch 96/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0722 - mse: 0.0722\n",
      "Epoch 97/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0720 - mse: 0.0720\n",
      "Epoch 98/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0721 - mse: 0.0721\n",
      "Epoch 99/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0716 - mse: 0.0716\n",
      "Epoch 100/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0715 - mse: 0.0715\n",
      "Epoch 101/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0715 - mse: 0.0715\n",
      "Epoch 102/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0715 - mse: 0.0715\n",
      "Epoch 103/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0707 - mse: 0.0707\n",
      "Epoch 104/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0700 - mse: 0.0700\n",
      "Epoch 105/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0697 - mse: 0.0697\n",
      "Epoch 106/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0683 - mse: 0.0683\n",
      "Epoch 107/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0674 - mse: 0.0674\n",
      "Epoch 108/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0669 - mse: 0.0669\n",
      "Epoch 109/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0667 - mse: 0.0667\n",
      "Epoch 110/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0662 - mse: 0.0662\n",
      "Epoch 111/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0661 - mse: 0.0661\n",
      "Epoch 112/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0657 - mse: 0.0657\n",
      "Epoch 113/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0655 - mse: 0.0655\n",
      "Epoch 114/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0655 - mse: 0.0655\n",
      "Epoch 115/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0654 - mse: 0.0654\n",
      "Epoch 116/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0654 - mse: 0.0654\n",
      "Epoch 117/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0649 - mse: 0.0649\n",
      "Epoch 118/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0643 - mse: 0.0643\n",
      "Epoch 119/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0637 - mse: 0.0637\n",
      "Epoch 120/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0630 - mse: 0.0630\n",
      "Epoch 121/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0626 - mse: 0.0626\n",
      "Epoch 122/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0623 - mse: 0.0623\n",
      "Epoch 123/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0618 - mse: 0.0618\n",
      "Epoch 124/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0614 - mse: 0.0614\n",
      "Epoch 125/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0611 - mse: 0.0611\n",
      "Epoch 126/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0615 - mse: 0.0615\n",
      "Epoch 127/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0604 - mse: 0.0604\n",
      "Epoch 128/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0599 - mse: 0.0599\n",
      "Epoch 129/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0597 - mse: 0.0597\n",
      "Epoch 130/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0593 - mse: 0.0593\n",
      "Epoch 131/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0583 - mse: 0.0583\n",
      "Epoch 132/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0585 - mse: 0.0585\n",
      "Epoch 133/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0569 - mse: 0.0569\n",
      "Epoch 134/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0567 - mse: 0.0567\n",
      "Epoch 135/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0558 - mse: 0.0558\n",
      "Epoch 136/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0553 - mse: 0.0553\n",
      "Epoch 137/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0548 - mse: 0.0548\n",
      "Epoch 138/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0545 - mse: 0.0545\n",
      "Epoch 139/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0537 - mse: 0.0537\n",
      "Epoch 140/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0530 - mse: 0.0530\n",
      "Epoch 141/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0530 - mse: 0.0530\n",
      "Epoch 142/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0529 - mse: 0.0529\n",
      "Epoch 143/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0527 - mse: 0.0527\n",
      "Epoch 144/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0527 - mse: 0.0527\n",
      "Epoch 145/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0528 - mse: 0.0528\n",
      "Epoch 146/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0524 - mse: 0.0524\n",
      "Epoch 147/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0523 - mse: 0.0523\n",
      "Epoch 148/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0519 - mse: 0.0519\n",
      "Epoch 149/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0518 - mse: 0.0518\n",
      "Epoch 150/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0515 - mse: 0.0515\n",
      "Epoch 151/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0515 - mse: 0.0515\n",
      "Epoch 152/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0515 - mse: 0.0515\n",
      "Epoch 153/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0514 - mse: 0.0514\n",
      "Epoch 154/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0512 - mse: 0.0512\n",
      "Epoch 155/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0510 - mse: 0.0510\n",
      "Epoch 156/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0508 - mse: 0.0508\n",
      "Epoch 157/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0506 - mse: 0.0506\n",
      "Epoch 158/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0503 - mse: 0.0503\n",
      "Epoch 159/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0500 - mse: 0.0500\n",
      "Epoch 160/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0492 - mse: 0.0492\n",
      "Epoch 161/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0490 - mse: 0.0490\n",
      "Epoch 162/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0487 - mse: 0.0487\n",
      "Epoch 163/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0486 - mse: 0.0486\n",
      "Epoch 164/500\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0481 - mse: 0.0481\n",
      "Epoch 165/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0478 - mse: 0.0478\n",
      "Epoch 166/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0468 - mse: 0.0468\n",
      "Epoch 167/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0463 - mse: 0.0463\n",
      "Epoch 168/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0452 - mse: 0.0452\n",
      "Epoch 169/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0449 - mse: 0.0449\n",
      "Epoch 170/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0446 - mse: 0.0446\n",
      "Epoch 171/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0445 - mse: 0.0445\n",
      "Epoch 172/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0444 - mse: 0.0444\n",
      "Epoch 173/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0443 - mse: 0.0443\n",
      "Epoch 174/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0442 - mse: 0.0442\n",
      "Epoch 175/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0439 - mse: 0.0439\n",
      "Epoch 176/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0438 - mse: 0.0438\n",
      "Epoch 177/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0434 - mse: 0.0434\n",
      "Epoch 178/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0431 - mse: 0.0431\n",
      "Epoch 179/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0428 - mse: 0.0428\n",
      "Epoch 180/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0426 - mse: 0.0426\n",
      "Epoch 181/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0424 - mse: 0.0424\n",
      "Epoch 182/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0423 - mse: 0.0423\n",
      "Epoch 183/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0424 - mse: 0.0424\n",
      "Epoch 184/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0420 - mse: 0.0420\n",
      "Epoch 185/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0423 - mse: 0.0423\n",
      "Epoch 186/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0416 - mse: 0.0416\n",
      "Epoch 187/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0416 - mse: 0.0416\n",
      "Epoch 188/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0415 - mse: 0.0415\n",
      "Epoch 189/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0413 - mse: 0.0413\n",
      "Epoch 190/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0411 - mse: 0.0411\n",
      "Epoch 191/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0410 - mse: 0.0410\n",
      "Epoch 192/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0407 - mse: 0.0407\n",
      "Epoch 193/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0403 - mse: 0.0403\n",
      "Epoch 194/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0405 - mse: 0.0405\n",
      "Epoch 195/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0401 - mse: 0.0401\n",
      "Epoch 196/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0403 - mse: 0.0403\n",
      "Epoch 197/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0401 - mse: 0.0401\n",
      "Epoch 198/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0401 - mse: 0.0401\n",
      "Epoch 199/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0397 - mse: 0.0397\n",
      "Epoch 200/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0394 - mse: 0.0394\n",
      "Epoch 201/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0393 - mse: 0.0393\n",
      "Epoch 202/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0391 - mse: 0.0391\n",
      "Epoch 203/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0389 - mse: 0.0389\n",
      "Epoch 204/500\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0385 - mse: 0.0385\n",
      "Epoch 205/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0383 - mse: 0.0383\n",
      "Epoch 206/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0377 - mse: 0.0377\n",
      "Epoch 207/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0373 - mse: 0.0373\n",
      "Epoch 208/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0367 - mse: 0.0367\n",
      "Epoch 209/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0365 - mse: 0.0365\n",
      "Epoch 210/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0359 - mse: 0.0359\n",
      "Epoch 211/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0357 - mse: 0.0357\n",
      "Epoch 212/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0358 - mse: 0.0358\n",
      "Epoch 213/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0356 - mse: 0.0356\n",
      "Epoch 214/500\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0357 - mse: 0.0357\n",
      "Epoch 215/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0356 - mse: 0.0356\n",
      "Epoch 216/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0352 - mse: 0.0352\n",
      "Epoch 217/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0354 - mse: 0.0354\n",
      "Epoch 218/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0351 - mse: 0.0351\n",
      "Epoch 219/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0352 - mse: 0.0352\n",
      "Epoch 220/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0350 - mse: 0.0350\n",
      "Epoch 221/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0351 - mse: 0.0351\n",
      "Epoch 222/500\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0350 - mse: 0.0350\n",
      "Epoch 223/500\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0350 - mse: 0.0350\n",
      "Epoch 00223: early stopping\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Model Fitting \"\"\"\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(512, input_dim=train_x.shape[1], activation='relu', kernel_initializer='he_normal', bias_initializer='zeros'),\n",
    "    Dense(128, activation='relu', kernel_initializer='he_normal', bias_initializer='zeros'),\n",
    "    Dense(64, activation='relu', kernel_initializer='he_normal', bias_initializer='zeros'),\n",
    "    Dense(128, activation='relu', kernel_initializer='he_normal', bias_initializer='zeros'),\n",
    "    Dense(512, activation='relu', kernel_initializer='he_normal', bias_initializer='zeros'),\n",
    "    Dense(train_x.shape[1], activation='relu')  \n",
    "])\n",
    "adam = Adam(lr=model_config['train']['learning_rate'], beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam, loss='mse', metrics=['mse'])\n",
    "early_stop = EarlyStopping(monitor='mse', patience=3, verbose=1, min_delta=0.00001)\n",
    "print(model.summary())\n",
    "ai_history = model.fit(train_x.values, train_x.values, epochs=model_config['train']['epochs'], batch_size=model_config['train']['batch_size'], verbose=1, shuffle=True, callbacks=[early_stop])\n",
    "model.save('{}/ot_model/{}.h5'.format(pwd, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faca00dc750>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(ai_history.history.keys())\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(ai_history.history['loss'], 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICTION VERSION SETTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREDICTION VERSION SETTING\n",
    "start = datetime.now().replace(microsecond=0) + timedelta(hours=9)\n",
    "pred_version = start.strftime(\"%Y%m%d_%H\")\n",
    "# pred_version = '20211102_13'\n",
    "\n",
    "for timerange in range(500):\n",
    "    if not os.path.exists(pwd+'/ot_model/'+pred_version):\n",
    "        new_time = start - timedelta(hours=timerange+1)\n",
    "        pred_version = new_time.strftime(\"%Y%m%d_%H\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test data preprocessing\n",
    "test_x = scale_module(test_x, mode = 'trans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('{}/ot_model/{}.h5'.format(pwd, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY_SCORE : 0.9517304189435337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2066,   24],\n",
       "       [  82,   24]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_x.values)\n",
    "\n",
    "# Using RMSE\n",
    "rmse = np.mean(np.power(test_x - pred, 2), axis=1)\n",
    "\n",
    "temp = pd.DataFrame()\n",
    "temp['rmse'] = rmse.values\n",
    "temp['true'] = test_y.values\n",
    "temp['threshold'] = temp['rmse'].rolling(10).mean()\n",
    "temp['pred'] = np.where(temp['rmse']>temp['threshold']*1.5,1,0)\n",
    "\n",
    "print(\"ACCURACY_SCORE : {}\".format(accuracy_score(temp['true'], temp['pred'])))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(temp['true'], temp['pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result insert to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x['ai_label_true'] = temp['true'].values\n",
    "test_x['ai_label_pred'] = temp['pred'].values\n",
    "test_x['rmse'] = temp['rmse'].values\n",
    "\n",
    "label_df = test_x[['ai_label_true', 'ai_label_pred', 'rmse']].reset_index(drop = False)\n",
    "label_df.rename(columns = {'time':'logtime'}, inplace = True)\n",
    "\n",
    "insert_df = pd.DataFrame(columns = ['logtime','tag_name','tag_value'], data = test_x.stack().reset_index().values)\n",
    "insert_df = pd.merge(insert_df, label_df, on = ['logtime'])\n",
    "insert_df['version'] = pred_version\n",
    "\n",
    "insert_df['logtime'] = pd.to_datetime(insert_df['logtime'])\n",
    "insert_df['tag_value'] = insert_df['tag_value'].astype('float')\n",
    "insert_df['ai_label_true'] = np.where(insert_df['ai_label_true'] == 1, 'NORMAL', 'ANOMALY')\n",
    "insert_df['ai_label_pred'] = np.where(insert_df['ai_label_pred'] == 1, 'NORMAL', 'ANOMALY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute_ch(\"INSERT INTO dti.kisa_ot_anomaly_detection_result VALUES\", insert_df.to_dict('records'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
