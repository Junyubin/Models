from auto_profiling_model import *
from auto_profiling_utils import *
from base_component import *
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import os
import logging
import warnings
warnings.filterwarnings('ignore')

pwd = os.getcwd()
print('Enter the mode')        
mode = input()

class ap_model():
    
    def ap_train():
        """ Version Setting"""    
        model_config = load_json('model_config.json')
        start = datetime.now().replace(microsecond=0) + timedelta(hours=9)
        train_version = start.strftime("%Y%m%d_%H")
        if not os.path.exists(pwd + '/' + model_config['common']['model_path'] + '/' + train_version):
            os.makedirs(pwd + '/' + model_config['common']['model_path'] + '/' + train_version)   
        print("*"*10 + 'Train Version : {}'.format(train_version) + "*"*10)

        """ Data Load """
        data = pd.DataFrame()
        for i in ['normal', 'SQL_INJECTION', 'XSS', 'BEACONING', 'CREDENTIAL']:
            print(i)
            data, meta = execute_ch("select * from dti.dti_sh_demo_log WHERE hash = '{}' limit 10000".format(i))
            feats = [m[0] for m in meta]
            globals()['{}_df'.format(i)] = pd.DataFrame(data, columns = feats)
        data = pd.concat([globals()['{}_df'.format('normal')], globals()['{}_df'.format('SQL_INJECTION')], globals()['{}_df'.format('XSS')], globals()['{}_df'.format('BEACONING')], globals()['{}_df'.format('CREDENTIAL')]])
        data_y = data[['hash']]
        print(data_y['hash'].value_counts())
        data_x = data.drop('hash', axis = 1)
        data_x['all'] = data_x[['http_host']].values + ' ' +data[['http_agent']].values + ' ' +data[['http_query']].values

        """ Data Split """
        train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.3, random_state=1004)
        train_x.reset_index(drop = True, inplace = True)
        test_x.reset_index(drop = True, inplace = True)
        train_y.reset_index(drop = True, inplace = True)
        test_y.reset_index(drop = True, inplace = True)
        valid_y = test_y.copy()
        save_test_x = test_x.copy()
        print(f"No. of training examples: {train_x.shape[0]}")
        print(f"No. of testing examples: {test_x.shape[0]}")
        print(train_y['hash'].value_counts())
        print(test_y['hash'].value_counts())

        """ Data Preprocessing """
        train_prep = DataPreprocessing(version=train_version, mode='train', config=model_config)
        train_x = train_prep.vec_module(train_x, col_list = 'all')
        train_x = train_prep.scale_module(train_x)
        train_y = train_prep.encoder_module(train_y)
        print("Train X Data Shape : {}".format(train_x.shape))
        print("Train Y Data Shape : {}".format(train_y.shape))
        train_prep.save_model(list(train_y), 'train_label')

        """ Model Fitting """
        ## Decision Tree
        model = DecisionTreeClassification(version=train_version, mode='train', config=model_config)
        model.fit_decision_tree(train_x, train_y)
        true, pred = model.validation(train_x, train_y)
        
        ## Cnn Model
        for i in list(train_y):
            if i == 'normal':
                pass
            else:
                print("\n ******** {} MODEL FITTING START ********".format(i))
                normal_y = train_y[train_y['normal'] == 1].copy()
                attack_y = train_y[train_y[i] == 1].copy()
                temp_y = pd.concat([normal_y, attack_y])
                temp_y = temp_y[['normal',i]].copy()
                temp_x = train_x.iloc[temp_y.index]
                random_idx = np.random.permutation(len(temp_x))
                temp_x = temp_x.iloc[random_idx]
                temp_y = temp_y.iloc[random_idx]

                cnn_train_x = np.array(temp_x).reshape(temp_x.shape[0], 1, temp_x.shape[1], 1)
                cnn_train_y = np.array(temp_y).reshape(temp_y.shape[0], -1)        
                model_config["x_data_shape"] = cnn_train_x.shape
                model_config["y_data_shape"] = cnn_train_y.shape
                model_config["att_name"] = i
                print(cnn_train_x.shape)
                model = AttackClassification(version=train_version, mode='train', config=model_config)

                _, globals()['ai_history_{}'.format(i)] = model.optimize_nn(cnn_train_x, cnn_train_y)
                true, pred = model.validation(cnn_train_x, cnn_train_y)
                print("{} MODEL FITTING FINISH".format(i))

        
        return 'OK'
    
    def ap_predict():
        """ Version Setting"""
        model_config = load_json('model_config.json')         
        start = datetime.now().replace(microsecond=0) + timedelta(hours=9)
        pred_version = start.strftime("%Y%m%d_%H")
        for timerange in range(500):
            if not os.path.exists('{}/{}/{}'.format(pwd, model_config['common']['model_path'],pred_version)):
                new_time = start - timedelta(hours=timerange+1)
                pred_version = new_time.strftime("%Y%m%d_%H")
            else:
                break        
        print("*"*10 + 'Predict Version : {}'.format(pred_version) + "*"*10)

        """ Data Load """
        data = pd.DataFrame()
        for i in ['normal', 'SQL_INJECTION', 'XSS', 'BEACONING', 'CREDENTIAL']:
            print(i)
            data, meta = execute_ch("select * from dti.dti_sh_demo_log WHERE hash = '{}' limit 10000".format(i))
            feats = [m[0] for m in meta]
            globals()['{}_df'.format(i)] = pd.DataFrame(data, columns = feats)
        data = pd.concat([globals()['{}_df'.format('normal')], globals()['{}_df'.format('SQL_INJECTION')], globals()['{}_df'.format('XSS')], globals()['{}_df'.format('BEACONING')], globals()['{}_df'.format('CREDENTIAL')]])
        data_y = data[['hash']]
        data_x = data.drop('hash', axis = 1)
        data_x['all'] = data_x[['http_host']].values + ' ' +data[['http_agent']].values + ' ' +data[['http_query']].values

        """ Data Split """
        train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.3, random_state=1004)
        train_x.reset_index(drop = True, inplace = True)
        test_x.reset_index(drop = True, inplace = True)
        train_y.reset_index(drop = True, inplace = True)
        test_y.reset_index(drop = True, inplace = True)
        valid_y = test_y.copy()
        save_test_x = test_x.copy()
        print(f"No. of training examples: {train_x.shape[0]}")
        print(f"No. of testing examples: {test_x.shape[0]}")
        print(train_y['hash'].value_counts())
        print(test_y['hash'].value_counts())
        
        """ Data Preprocessing """        
        test_prep = DataPreprocessing(version=pred_version, mode='test', config=model_config)
        test_x = test_prep.vec_module(test_x, col_list = 'all')
        test_x = test_prep.scale_module(test_x)
        test_y = test_prep.encoder_module(test_y)
        print("Test X Data Shape : {}".format(test_x.shape))
        print("Test Y Data Shape : {}".format(test_y.shape))                

        """ Data Prediction """
        ## Decision Tree
        model = DecisionTreeClassification(version=pred_version, mode='test', config=model_config)
        true, pred = model.validation(test_x, test_y)
        train_label = test_prep.load_model('train_label')
        dt_pred = [train_label[i] for i in pred]        
        
        ## Cnn Model
        save_test_x['ai_label_pred'] = np.NaN

        for i in list(set(dt_pred)):
            y_index = [index for index, att_name in enumerate(dt_pred) if att_name == i]

            if i == 'normal':
                save_test_x.at[y_index,'ai_label_pred'] = 'NORMAL'
            else:
                print("\n ******** {} MODEL PREDICTION START ********".format(i))
                temp_x = test_x.iloc[y_index]
                temp_y = test_y.iloc[y_index][['normal',i]].copy()

                cnn_test_x = np.array(temp_x).reshape(temp_x.shape[0], 1, temp_x.shape[1], 1)
                cnn_test_y = np.array(temp_y).reshape(temp_y.shape[0], -1)        
                model_config["x_data_shape"] = cnn_test_x.shape
                model_config["y_data_shape"] = cnn_test_y.shape
                model_config["att_name"] = i

                model = AttackClassification(version=pred_version, mode='predict', config=model_config)
                true, pred = model.validation(cnn_test_x, cnn_test_y)
                save_test_x.at[y_index,'ai_label_pred'] = pred.tolist()
                save_test_x['ai_label_pred'] = np.where(save_test_x['ai_label_pred'] == 1, i, save_test_x['ai_label_pred'])
                print("{} MODEL PREDICTION FINISH".format(i))
        save_test_x['ai_label_pred'] = np.where(save_test_x['ai_label_pred'].isin(['0.0',0,'nan']), 'NORMAL', save_test_x['ai_label_pred'])
        save_test_x['version'] = pred_version
        
        valid_y['hash'] = np.where(valid_y['hash'] == 'normal', 'NORMAL', valid_y['hash'])
        save_test_x['ai_label_true'] = valid_y['hash']
        print("ACCURACY SCORE : {}".format(accuracy_score(valid_y,save_test_x['ai_label_pred'])))
        print("CONFUSION MATRIX : \n {}".format(confusion_matrix(valid_y, save_test_x['ai_label_pred'])))

        """ Data Insert """
        execute_ch("INSERT INTO dti.kisa_auto_profiling_result VALUES", save_test_x.to_dict('records'))
        return 'OK'

def main(mode):
    if mode == 'train':
        ap_model.ap_train()
    elif mode == 'predict':
        ap_model.ap_predict()

main(mode)